{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a8bbbab-c4d6-4d33-9deb-deeee3ddebc2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Imports e config dos módulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eaddd15d-6e31-4192-9589-01f0b17a8fec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Image\n",
    "import warnings\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif, SequentialFeatureSelector, SelectKBest\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer, MissingIndicator\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict, LeaveOneOut, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import classification_report, recall_score, precision_score, make_scorer, f1_score\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from boruta import BorutaPy\n",
    "from genetic_selection import GeneticSelectionCV\n",
    "from collections import Counter\n",
    "from hyperopt import fmin, tpe, hp\n",
    "from hyperopt.pyll.base import scope\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "from functools import partial\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "# from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d809f8af-ee4a-45dc-9a98-01a13c5bed94",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# pd.set_option('max_columns', None)\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48fb3f5c-53cf-4595-a1ef-9b0b0968096d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b91e37e-aecb-4b0b-b32c-ab379846f9d7",
     "showTitle": true,
     "title": "Read"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mclar\\AppData\\Local\\Temp\\ipykernel_2476\\1568157318.py:1: DtypeWarning: Columns (9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../data/interim/hans_outcome.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/interim/hans_outcome.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e42b76e-9dac-40e9-a095-20edbd7528fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113837, 39)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d748a056-f7cc-40a9-946a-93958a937811",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Agrupamento e remoção de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a54241f-ac2a-4605-9b27-d7bb118a3720",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "target = 'TPALTA_N'\n",
    "feats = df.drop(target, axis=1).columns\n",
    "num_feats = [feat for feat in feats if df[feat].dtype != 'O']\n",
    "cat_feats = [feat for feat in feats if feat not in num_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77a9fbf9-0637-4fbe-8cce-a620a1bdbfb9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# remove colunas com classes muito dominantes\n",
    "def drop_low_variance(col):\n",
    "    if df[col].nunique() == 1:\n",
    "        return True\n",
    "    elif df[col].value_counts(1).iloc[0] > 0.9:\n",
    "        return True\n",
    "    elif df[col].value_counts().iloc[0] < df[col].isna().sum():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "low_var_feats = [col for col in cat_feats if drop_low_variance(col)]\n",
    "cat_feats = [feat for feat in cat_feats if feat not in low_var_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2798c17-b237-4d1b-8e32-1882cddb115e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DT_DIAG',\n",
       " 'CS_SEXO',\n",
       " 'CS_ESCOL_N',\n",
       " 'DTINICTRAT',\n",
       " 'UFATUAL',\n",
       " 'DT_NOTI_AT',\n",
       " 'DTALTA_N']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_feats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b6495ac-933c-4d97-a2e4-aa072274df61",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# ML Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5005bbe-2f3f-407a-aa28-edca82e535d1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Feature transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14e83163-fd37-4e7f-84c6-dc19494a2e29",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class GBMFeatTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, EBM=False):\n",
    "        self.EBM = EBM\n",
    "        self.num_feats_means = dict()\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        if self.EBM:\n",
    "            for col in X.columns:\n",
    "                if X[col].dtype != 'O':\n",
    "                    self.num_feats_means[col] = X[col].mean()\n",
    "        return self\n",
    "            \n",
    "    def transform(self, X, y=None):\n",
    "        ret = X.copy()\n",
    "        if not self.EBM:\n",
    "            for col in ret.columns:\n",
    "                if ret[col].dtype == 'O':\n",
    "                    ret[col] = ret[col].astype('category')\n",
    "        else:\n",
    "            for col in self.num_feats_means:\n",
    "                ret[col] = ret[col].fillna(self.num_feats_means[col])\n",
    "        return ret\n",
    "        \n",
    "general_num_transformer = FeatureUnion(    \n",
    "    [\n",
    "        ('num_pipe', Pipeline(\n",
    "            [\n",
    "                ('norm', StandardScaler()),\n",
    "                ('nan_input', SimpleImputer())\n",
    "            ]\n",
    "        )),\n",
    "        ('nan_flag', MissingIndicator(error_on_new=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "general_feat_transformer = ColumnTransformer(\n",
    "    [\n",
    "        ('num_trans', general_num_transformer, num_feats),\n",
    "        ('cat_trans', OneHotEncoder(handle_unknown='ignore'), cat_feats)    \n",
    "    ],\n",
    "    remainder='passthrough', sparse_threshold=0\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5b501ad-eb34-420d-aed8-a3aecb69f891",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Nested K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b595d88-a168-4def-8b1f-047615f20b90",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class NestedKFoldOpt():\n",
    "    def __init__(self, ml_model, opt_space, loss_metric, outer_cv, inner_cv, \n",
    "                 opt_type='bayes', max_evals=10):\n",
    "        self.ml_model = ml_model\n",
    "        self.opt_space = opt_space\n",
    "        self.loss_metric = loss_metric\n",
    "        self.opt_type = opt_type\n",
    "        self.max_evals = max_evals\n",
    "        self.outer_cv = outer_cv\n",
    "        self.inner_cv = inner_cv\n",
    "        self.metrics_ = None\n",
    "        self.metrics_oof_ = None\n",
    "        self.metrics_dist_ = None\n",
    "        self.best_hyperparameters_ = None\n",
    "        \n",
    "    def objective(self, x, data):\n",
    "        model = clone(self.ml_model).set_params(**x)\n",
    "        \n",
    "        preds = cross_val_predict(model, data[0], data[1], cv=self.inner_cv, n_jobs=-1)\n",
    "        \n",
    "        return -self.loss_metric(data[1], preds)     \n",
    "        \n",
    "    \n",
    "    def optimize(self, X, y):\n",
    "        if self.opt_type == 'bayes':\n",
    "            obj = partial(self.objective, data=(X, y))\n",
    "            best = fmin(obj, space=self.opt_space, algo=tpe.suggest, \n",
    "                        max_evals=self.max_evals, return_argmin=False)\n",
    "        else:\n",
    "            loss_metric = make_scorer(self.loss_metric)\n",
    "            best = GridSearchCV(self.ml_model, self.opt_space, scoring=loss_metric,\n",
    "                                n_jobs=-1, cv=self.inner_cv, verbose=3).\\\n",
    "                   fit(X, y).best_params_\n",
    "        return best\n",
    "    \n",
    "    def nested_kfold(self, X, y):\n",
    "        recall_0 = []\n",
    "        recall_1 = []\n",
    "        precision_0 = []\n",
    "        precision_1 = []\n",
    "        oof = np.zeros(len(X))\n",
    "        for train_idx, val_idx in self.outer_cv.split(X, y):\n",
    "            X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "            X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "            hypers = self.optimize(X_train, y_train)\n",
    "            model = clone(self.ml_model).set_params(**hypers).fit(X_train, y_train)\n",
    "            preds = model.predict(X_val)\n",
    "            oof[val_idx] = preds \n",
    "            recall_0.append(recall_score(y_val, preds, pos_label=0))\n",
    "            recall_1.append(recall_score(y_val, preds, pos_label=1))\n",
    "            precision_0.append(precision_score(y_val, preds, pos_label=0))\n",
    "            precision_1.append(precision_score(y_val, preds, pos_label=1))\n",
    "        self.metrics_ = pd.DataFrame({'recall': [np.mean(recall_0), np.mean(recall_1)],\n",
    "                                      'recall_std': [np.std(recall_0), np.std(recall_1)],\n",
    "                                      'precision': [np.mean(precision_0), np.mean(precision_1)],\n",
    "                                      'precision_std': [np.std(precision_0), np.std(precision_1)]},\n",
    "                                     index=['class_0', 'class_1'])\n",
    "        self.metrics_oof_ = pd.DataFrame({'recall': [recall_score(y, oof, pos_label=0), recall_score(y, oof)],\n",
    "                                          'precision': [precision_score(y, oof, pos_label=0), precision_score(y, oof)],\n",
    "                                          'f1 score': [f1_score(y, oof, pos_label=0), f1_score(y, oof)],\n",
    "                                          'accuracy': [accuracy_score(y, oof)],\n",
    "                                         },\n",
    "                                         index=['class_0', 'class_1'])\n",
    "        self.metrics_dist_ = {'recall_0': recall_0, 'recall_1': recall_1,\n",
    "                              'precision_0': precision_0, 'precision_1': precision_1}\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        X = X.copy()\n",
    "        y = y.copy()\n",
    "        self.nested_kfold(X, y)\n",
    "        self.best_hyperparameters_ = self.optimize(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6598362a-dae2-453e-bc72-262f45a60d69",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X = df[num_feats + cat_feats].copy()\n",
    "le = LabelEncoder().fit(df[target])\n",
    "y = pd.Series(le.transform(df[target]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "248cde31-a91c-4bc9-8e51-404b16a73e48",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "62e11928-783c-4fc8-993c-11c04ec45bb2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "base_model = RandomForestClassifier(n_jobs=-1, max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d91ae324-01a8-4e12-a228-1dc6aa0fe161",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_num = GBMFeatTransformer().fit_transform(X)\n",
    "for col in X_num.columns:\n",
    "    if X_num[col].dtype.name == 'category':\n",
    "        X_num[col] = X_num[col].cat.codes\n",
    "    else:\n",
    "        X_num[col].fillna(X_num[col].median(), inplace=True)\n",
    "        \n",
    "columns = X_num.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5ecd2d5-adeb-4343-a304-114c7824bd4e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.04      0.07      6880\n",
      "           1       0.94      1.00      0.97    106957\n",
      "\n",
      "    accuracy                           0.94    113837\n",
      "   macro avg       0.93      0.52      0.52    113837\n",
      "weighted avg       0.94      0.94      0.92    113837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, cross_val_predict(base_model, X_num, y, n_jobs=-1,\n",
    "  cv=StratifiedKFold(shuffle=True, random_state=9))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d69e16a8-b362-46d1-98d2-52e9f6afaa8e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "996ec863-02f8-48f5-a42a-5ebf44b2896a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BorutaPy(estimator=RandomForestClassifier(max_depth=5, n_estimators=167,\n",
       "                                          n_jobs=-1,\n",
       "                                          random_state=RandomState(MT19937) at 0x16171C80D40),\n",
       "         n_estimators=&#x27;auto&#x27;, perc=90,\n",
       "         random_state=RandomState(MT19937) at 0x16171C80D40)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BorutaPy</label><div class=\"sk-toggleable__content\"><pre>BorutaPy(estimator=RandomForestClassifier(max_depth=5, n_estimators=167,\n",
       "                                          n_jobs=-1,\n",
       "                                          random_state=RandomState(MT19937) at 0x16171C80D40),\n",
       "         n_estimators=&#x27;auto&#x27;, perc=90,\n",
       "         random_state=RandomState(MT19937) at 0x16171C80D40)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=5, n_estimators=167, n_jobs=-1,\n",
       "                       random_state=RandomState(MT19937) at 0x16171C80D40)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=5, n_estimators=167, n_jobs=-1,\n",
       "                       random_state=RandomState(MT19937) at 0x16171C80D40)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BorutaPy(estimator=RandomForestClassifier(max_depth=5, n_estimators=167,\n",
       "                                          n_jobs=-1,\n",
       "                                          random_state=RandomState(MT19937) at 0x16171C80D40),\n",
       "         n_estimators='auto', perc=90,\n",
       "         random_state=RandomState(MT19937) at 0x16171C80D40)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bor_selector = BorutaPy(base_model, n_estimators='auto', perc=90, max_iter=100)\n",
    "bor_selector.fit(X_num.values, y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "256c75f5-069f-4295-a1fb-535dfd05ef6d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SG_UF_NOT', 'ID_MUNICIP', 'ID_REGIONA', 'ID_UNIDADE', 'ANO_NASC',\n",
       "       'SG_UF', 'ID_MN_RESI', 'ID_RG_RESI', 'FORMACLINI', 'AVALIA_N',\n",
       "       'CLASSOPERA', 'MODODETECT', 'BACILOSCOP', 'ESQ_INI_N',\n",
       "       'ID_MUNI_AT', 'ID_UNID_AT', 'UFRESAT', 'MUNIRESAT', 'CLASSATUAL',\n",
       "       'AVAL_ATU_N', 'ESQ_ATU_N', 'EPIS_RACIO', 'NU_ANO', 'NU_LESOES',\n",
       "       'CONTREG', 'DOSE_RECEB', 'CONTEXAM', 'DURACAO_TRAT', 'DT_DIAG',\n",
       "       'DTINICTRAT', 'UFATUAL', 'DT_NOTI_AT', 'DTALTA_N'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns[bor_selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b796d0c7-e0ec-488a-8952-359bded04d2f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MODODETECT', 'BACILOSCOP', 'ID_MN_RESI', 'CS_RACA', 'CS_GESTANT',\n",
       "       'CS_ESCOL_N', 'CS_SEXO'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom_boruta = columns[bor_selector.ranking_.argsort()[-(len(columns)-30):]]\n",
    "bottom_boruta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8bacfed-89b3-4904-8e64-9b0ea57dd998",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Sequential Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4db03f3-89c5-4167-89d6-0a83eed7a122",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m sb_selector \u001b[39m=\u001b[39m SequentialFeatureSelector(base_model, n_features_to_select\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m, direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbackward\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      2\u001b[0m                                         scoring\u001b[39m=\u001b[39mmake_scorer(f1_score, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m'\u001b[39m), \n\u001b[0;32m      3\u001b[0m                                         cv\u001b[39m=\u001b[39mStratifiedKFold(shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, random_state\u001b[39m=\u001b[39m\u001b[39m9\u001b[39m), n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m sb_selector\u001b[39m.\u001b[39;49mfit(X_num, y)\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_sequential.py:268\u001b[0m, in \u001b[0;36mSequentialFeatureSelector.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    266\u001b[0m is_auto_select \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_to_select \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_iterations):\n\u001b[1;32m--> 268\u001b[0m     new_feature_idx, new_score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_best_new_feature_score(\n\u001b[0;32m    269\u001b[0m         cloned_estimator, X, y, current_mask\n\u001b[0;32m    270\u001b[0m     )\n\u001b[0;32m    271\u001b[0m     \u001b[39mif\u001b[39;00m is_auto_select \u001b[39mand\u001b[39;00m ((new_score \u001b[39m-\u001b[39m old_score) \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol):\n\u001b[0;32m    272\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_sequential.py:299\u001b[0m, in \u001b[0;36mSequentialFeatureSelector._get_best_new_feature_score\u001b[1;34m(self, estimator, X, y, current_mask)\u001b[0m\n\u001b[0;32m    297\u001b[0m         candidate_mask \u001b[39m=\u001b[39m \u001b[39m~\u001b[39mcandidate_mask\n\u001b[0;32m    298\u001b[0m     X_new \u001b[39m=\u001b[39m X[:, candidate_mask]\n\u001b[1;32m--> 299\u001b[0m     scores[feature_idx] \u001b[39m=\u001b[39m cross_val_score(\n\u001b[0;32m    300\u001b[0m         estimator,\n\u001b[0;32m    301\u001b[0m         X_new,\n\u001b[0;32m    302\u001b[0m         y,\n\u001b[0;32m    303\u001b[0m         cv\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcv,\n\u001b[0;32m    304\u001b[0m         scoring\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscoring,\n\u001b[0;32m    305\u001b[0m         n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    306\u001b[0m     )\u001b[39m.\u001b[39mmean()\n\u001b[0;32m    307\u001b[0m new_feature_idx \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(scores, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m feature_idx: scores[feature_idx])\n\u001b[0;32m    308\u001b[0m \u001b[39mreturn\u001b[39;00m new_feature_idx, scores[new_feature_idx]\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[0;32m    269\u001b[0m         X,\n\u001b[0;32m    270\u001b[0m         y,\n\u001b[0;32m    271\u001b[0m         scorers,\n\u001b[0;32m    272\u001b[0m         train,\n\u001b[0;32m    273\u001b[0m         test,\n\u001b[0;32m    274\u001b[0m         verbose,\n\u001b[0;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    276\u001b[0m         fit_params,\n\u001b[0;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[0;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[0;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    281\u001b[0m     )\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1061\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1061\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1062\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:938\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    936\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 938\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    939\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    940\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sb_selector = SequentialFeatureSelector(base_model, n_features_to_select=30, direction='backward',\n",
    "                                        scoring=make_scorer(f1_score, average='macro'), \n",
    "                                        cv=StratifiedKFold(shuffle=True, random_state=9), n_jobs=-1)\n",
    "sb_selector.fit(X_num, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c30f4472-1308-4690-a0ce-04bf12f32027",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bottom_sb = columns[~sb_selector.get_support()]\n",
    "bottom_sb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd658ae3-5639-4552-a24b-03f70ea8a36a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### M.I Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "afbfaca8-1940-44de-b80a-f4d9579d8393",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mi_selector = SelectKBest(mutual_info_classif, k=30).fit(X_num, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5fd1f3e-b14f-4735-9f30-bf2c32c07a72",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ANO_NASC', 'NU_LESOES', 'CONTREG', 'DT_DIAG', 'CS_ESCOL_N',\n",
       "       'DTINICTRAT', 'DT_NOTI_AT'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom_mi = columns[~mi_selector.get_support()]\n",
    "bottom_mi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a021df5-e9ea-4023-a8dc-1efe43f4591a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c6ffed2-ab18-4b63-a92a-615767b7e816",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ga_selector = GeneticSelectionCV(base_model, cv=StratifiedKFold(shuffle=True, random_state=9), \n",
    "                                 scoring=make_scorer(f1_score, average='macro'), max_features=30, \n",
    "                                 n_population=100, n_generations=40, n_gen_no_change=10)\n",
    "ga_selector.fit(X_num, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "996ab17e-9ab8-4090-8fa3-89c53501cdd9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bottom_ga = columns[~ga_selector.get_support()]\n",
    "bottom_ga"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc3444b0-698e-41ea-a5ef-7cbe91d4ed82",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Aggregation of the methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c71ba497-aad2-4198-826f-84a735b747ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# counts = pd.Series(dict(Counter(np.hstack([bottom_boruta, bottom_sb, bottom_mi, bottom_ga]))))\n",
    "counts = pd.Series(dict(Counter(np.hstack([bottom_boruta, bottom_mi]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8d4d9e8-e77b-4fe5-8ae5-6f438065e2ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CS_ESCOL_N'], dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_decide = counts[counts>1].index\n",
    "cols_to_decide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "722c893b-41c2-403c-be7b-519d669cdf29",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cols_to_remove = cols_to_decide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5308989a-c397-4aa6-aac4-420bf0354aa9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113837, 36)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fs = X.drop(cols_to_remove, axis=1)\n",
    "X_fs.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf295ce3-61b8-432c-ad8e-0c96fc6d183d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Algorithms Comparison"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f9e8f10-9b4a-452a-bd48-daedf6587d32",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "faf32c96-8e7d-4997-9a9e-4ed2b020696a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lr_pipe = Pipeline(\n",
    "  [\n",
    "      ('feat_trans', general_feat_transformer),\n",
    "      ('over', RandomOverSampler(random_state=9)),\n",
    "      ('logreg', LogisticRegression(random_state = 0))\n",
    "]\n",
    ")\n",
    "\n",
    "lr_opt_space = {'logreg__solver': hp.choice('logreg__solver', ['liblinear', 'lbfgs']),\n",
    "                'logreg__C': hp.loguniform('logreg__C', np.log(1e-5), np.log(100))}\n",
    "               \n",
    "lr_opt_space = {'logreg__warm_start' : hp.choice('logreg__warm_start', [True, False]),\n",
    "                'logreg__fit_intercept' : hp.choice('logreg__fit_intercept', [True, False]),\n",
    "                'logreg__tol' : hp.uniform('logreg__tol', 0.00001, 0.0001),\n",
    "                'logreg__C' : hp.uniform('logreg__C', 0.05, 3),\n",
    "                'logreg__solver' : hp.choice('logreg__solver', ['newton-cg', 'lbfgs', 'liblinear']),\n",
    "                'logreg__multi_class' : 'auto',\n",
    "                'logreg__class_weight' : 'balanced'}\n",
    "\n",
    "lr_opt = NestedKFoldOpt(lr_pipe, lr_opt_space, partial(f1_score, average='macro'), \n",
    "                      outer_cv=StratifiedKFold(2, shuffle=True, random_state=9), \n",
    "                      inner_cv=StratifiedKFold(2, shuffle=True, random_state=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad7862e5-669b-41cb-a89a-d261867943ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Encoders require their input to be uniformly strings or numbers. Got ['float', 'str']\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:04<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Encoders require their input to be uniformly strings or numbers. Got ['float', 'str']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_encode.py\", line 173, in _unique_python\n    uniques = sorted(uniques_set)\nTypeError: '<' not supported between instances of 'str' and 'float'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 436, in _process_worker\n    r = call_item()\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 288, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n    return [func(*args, **kwargs)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n    return self.function(*args, **kwargs)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 1068, in _fit_and_predict\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 293, in fit\n    Xt, yt = self._fit(X, y, **fit_params_steps)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 240, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 727, in fit_transform\n    result = self._fit_transform(X, y, _fit_transform_one)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 658, in _fit_transform\n    return Parallel(n_jobs=self.n_jobs)(\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n    return super().__call__(iterable_with_config)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1051, in __call__\n    while self.dispatch_one_batch(iterator):\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 864, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 782, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n    result = ImmediateResult(func)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n    self.results = batch()\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n    return [func(*args, **kwargs)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n    return self.function(*args, **kwargs)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 862, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 838, in fit\n    fit_results = self._fit(\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 93, in _fit\n    result = _unique(Xi, return_counts=return_counts)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_encode.py\", line 41, in _unique\n    return _unique_python(\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_encode.py\", line 178, in _unique_python\n    raise TypeError(\nTypeError: Encoders require their input to be uniformly strings or numbers. Got ['float', 'str']\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lr_opt\u001b[39m.\u001b[39;49mfit(X, y)\n",
      "Cell \u001b[1;32mIn[24], line 70\u001b[0m, in \u001b[0;36mNestedKFoldOpt.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     68\u001b[0m X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m     69\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m---> 70\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnested_kfold(X, y)\n\u001b[0;32m     71\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_hyperparameters_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimize(X, y)\n",
      "Cell \u001b[1;32mIn[24], line 45\u001b[0m, in \u001b[0;36mNestedKFoldOpt.nested_kfold\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     43\u001b[0m X_train, y_train \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39miloc[train_idx], y\u001b[39m.\u001b[39miloc[train_idx]\n\u001b[0;32m     44\u001b[0m X_val, y_val \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39miloc[val_idx], y\u001b[39m.\u001b[39miloc[val_idx]\n\u001b[1;32m---> 45\u001b[0m hypers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimize(X_train, y_train)\n\u001b[0;32m     46\u001b[0m model \u001b[39m=\u001b[39m clone(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mml_model)\u001b[39m.\u001b[39mset_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhypers)\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     47\u001b[0m preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_val)\n",
      "Cell \u001b[1;32mIn[24], line 27\u001b[0m, in \u001b[0;36mNestedKFoldOpt.optimize\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt_type \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbayes\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     26\u001b[0m     obj \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective, data\u001b[39m=\u001b[39m(X, y))\n\u001b[1;32m---> 27\u001b[0m     best \u001b[39m=\u001b[39m fmin(obj, space\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopt_space, algo\u001b[39m=\u001b[39;49mtpe\u001b[39m.\u001b[39;49msuggest, \n\u001b[0;32m     28\u001b[0m                 max_evals\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_evals, return_argmin\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     29\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     30\u001b[0m     loss_metric \u001b[39m=\u001b[39m make_scorer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_metric)\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[39m.\u001b[39mcatch_eval_exceptions \u001b[39m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[39m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m rval\u001b[39m.\u001b[39;49mexhaust()\n\u001b[0;32m    588\u001b[0m \u001b[39mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(trials\u001b[39m.\u001b[39mtrials) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexhaust\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_evals \u001b[39m-\u001b[39;49m n_done, block_until_done\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49masynchronous)\n\u001b[0;32m    365\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    297\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoll_interval_secs)\n\u001b[0;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[39m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mserial_evaluate()\n\u001b[0;32m    302\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[0;32m    303\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials_save_file \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m ctrl \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mCtrl(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials, current_trial\u001b[39m=\u001b[39mtrial)\n\u001b[0;32m    177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdomain\u001b[39m.\u001b[39;49mevaluate(spec, ctrl)\n\u001b[0;32m    179\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mjob exception: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mstr\u001b[39m(e))\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\hyperopt\\base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[39m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     \u001b[39m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[0;32m    886\u001b[0m     \u001b[39m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     pyll_rval \u001b[39m=\u001b[39m pyll\u001b[39m.\u001b[39mrec_eval(\n\u001b[0;32m    888\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpr,\n\u001b[0;32m    889\u001b[0m         memo\u001b[39m=\u001b[39mmemo,\n\u001b[0;32m    890\u001b[0m         print_node_on_error\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[1;32m--> 892\u001b[0m     rval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(pyll_rval)\n\u001b[0;32m    894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(rval, (\u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m, np\u001b[39m.\u001b[39mnumber)):\n\u001b[0;32m    895\u001b[0m     dict_rval \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mfloat\u001b[39m(rval), \u001b[39m\"\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[1;32mIn[24], line 19\u001b[0m, in \u001b[0;36mNestedKFoldOpt.objective\u001b[1;34m(self, x, data)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mobjective\u001b[39m(\u001b[39mself\u001b[39m, x, data):\n\u001b[0;32m     17\u001b[0m     model \u001b[39m=\u001b[39m clone(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mml_model)\u001b[39m.\u001b[39mset_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mx)\n\u001b[1;32m---> 19\u001b[0m     preds \u001b[39m=\u001b[39m cross_val_predict(model, data[\u001b[39m0\u001b[39;49m], data[\u001b[39m1\u001b[39;49m], cv\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minner_cv, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     21\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_metric(data[\u001b[39m1\u001b[39m], preds)\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:986\u001b[0m, in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    984\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    985\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 986\u001b[0m predictions \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    987\u001b[0m     delayed(_fit_and_predict)(\n\u001b[0;32m    988\u001b[0m         clone(estimator), X, y, train, test, verbose, fit_params, method\n\u001b[0;32m    989\u001b[0m     )\n\u001b[0;32m    990\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m splits\n\u001b[0;32m    991\u001b[0m )\n\u001b[0;32m    993\u001b[0m inv_test_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(\u001b[39mlen\u001b[39m(test_indices), dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n\u001b[0;32m    994\u001b[0m inv_test_indices[test_indices] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mlen\u001b[39m(test_indices))\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1061\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1061\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1062\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:938\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    936\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 938\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    939\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    940\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\concurrent\\futures\\_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    457\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 458\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    459\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: Encoders require their input to be uniformly strings or numbers. Got ['float', 'str']"
     ]
    }
   ],
   "source": [
    "lr_opt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7813b78d-3086-48dd-875a-52d88ea85e38",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lr_opt.metrics_oof_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf156317-6cf6-48e5-a323-b9b4ac347c8a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lr_opt.fit(X_fs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7930884-6fcb-49e5-86d3-ad3622dec472",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lr_opt.metrics_oof_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27dd2fae-3ab9-46cb-b305-4d8d231b183e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LGBMClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m rf_pipe \u001b[39m=\u001b[39m Pipeline(\n\u001b[0;32m      2\u001b[0m     [\n\u001b[0;32m      3\u001b[0m         (\u001b[39m'\u001b[39m\u001b[39mfeat_trans\u001b[39m\u001b[39m'\u001b[39m, general_feat_transformer),\n\u001b[0;32m      4\u001b[0m         (\u001b[39m'\u001b[39m\u001b[39mover\u001b[39m\u001b[39m'\u001b[39m, RandomOverSampler(random_state\u001b[39m=\u001b[39m\u001b[39m9\u001b[39m)),\n\u001b[1;32m----> 5\u001b[0m         (\u001b[39m'\u001b[39m\u001b[39mrf\u001b[39m\u001b[39m'\u001b[39m, LGBMClassifier(boosting_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrf\u001b[39m\u001b[39m'\u001b[39m, subsample_freq\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, min_child_samples\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m      6\u001b[0m     ]\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m rf_opt_space \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mrf__n_estimators\u001b[39m\u001b[39m'\u001b[39m: scope\u001b[39m.\u001b[39mint(hp\u001b[39m.\u001b[39mquniform(\u001b[39m'\u001b[39m\u001b[39mrf__n_estimators\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m300\u001b[39m, \u001b[39m10\u001b[39m)),\n\u001b[0;32m     10\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mrf__num_leaves\u001b[39m\u001b[39m'\u001b[39m: scope\u001b[39m.\u001b[39mint(hp\u001b[39m.\u001b[39mquniform(\u001b[39m'\u001b[39m\u001b[39mnum_leaves\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m100\u001b[39m, \u001b[39m1\u001b[39m)),\n\u001b[0;32m     11\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mrf__subsample\u001b[39m\u001b[39m'\u001b[39m: hp\u001b[39m.\u001b[39muniform(\u001b[39m'\u001b[39m\u001b[39mrf__subsample\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0.3\u001b[39m, \u001b[39m0.95\u001b[39m),\n\u001b[0;32m     12\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mrf__colsample_bytree\u001b[39m\u001b[39m'\u001b[39m: hp\u001b[39m.\u001b[39muniform(\u001b[39m'\u001b[39m\u001b[39mrf__colsample_bytree\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0.3\u001b[39m, \u001b[39m0.95\u001b[39m)}\n\u001b[0;32m     14\u001b[0m rf_opt \u001b[39m=\u001b[39m NestedKFoldOpt(rf_pipe, rf_opt_space, partial(f1_score, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m'\u001b[39m), \n\u001b[0;32m     15\u001b[0m                         outer_cv\u001b[39m=\u001b[39mStratifiedKFold(\u001b[39m10\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, random_state\u001b[39m=\u001b[39m\u001b[39m9\u001b[39m), \n\u001b[0;32m     16\u001b[0m                         inner_cv\u001b[39m=\u001b[39mStratifiedKFold(\u001b[39m10\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, random_state\u001b[39m=\u001b[39m\u001b[39m9\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LGBMClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "rf_pipe = Pipeline(\n",
    "    [\n",
    "        ('feat_trans', general_feat_transformer),\n",
    "        ('over', RandomOverSampler(random_state=9)),\n",
    "        ('rf', LGBMClassifier(boosting_type='rf', subsample_freq=1, min_child_samples=1))\n",
    "    ]\n",
    ")\n",
    "\n",
    "rf_opt_space = {'rf__n_estimators': scope.int(hp.quniform('rf__n_estimators', 50, 300, 10)),\n",
    "                'rf__num_leaves': scope.int(hp.quniform('num_leaves', 2, 100, 1)),\n",
    "                'rf__subsample': hp.uniform('rf__subsample', 0.3, 0.95),\n",
    "                'rf__colsample_bytree': hp.uniform('rf__colsample_bytree', 0.3, 0.95)}\n",
    "\n",
    "rf_opt = NestedKFoldOpt(rf_pipe, rf_opt_space, partial(f1_score, average='macro'), \n",
    "                        outer_cv=StratifiedKFold(10, shuffle=True, random_state=9), \n",
    "                        inner_cv=StratifiedKFold(10, shuffle=True, random_state=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_opt.fit(X_fs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_opt.metrics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_opt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_opt.metrics_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pipe = Pipeline(\n",
    "    [\n",
    "        ('feat_trans', general_feat_transformer),\n",
    "        ('over', RandomOverSampler(random_state=9)),\n",
    "        ('svm', SVC())\n",
    "    ]\n",
    ")\n",
    "\n",
    "svm_opt_space = {'svm__C': hp.loguniform('svm__C', np.log(1e-5), np.log(100)),\n",
    "                 'svm__gamma': hp.loguniform('svm__gamma', np.log(1e-6), np.log(10))}\n",
    "\n",
    "svm_opt = NestedKFoldOpt(svm_pipe, svm_opt_space, partial(f1_score, average='macro'), \n",
    "                        outer_cv=StratifiedKFold(10, shuffle=True, random_state=9), \n",
    "                        inner_cv=StratifiedKFold(10, shuffle=True, random_state=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_opt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_opt.metrics_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_pipe = Pipeline(\n",
    "    [\n",
    "        ('feat_trans', general_feat_transformer),\n",
    "        ('over', RandomOverSampler(random_state=9)),\n",
    "        ('sgd', SGDClassifier())\n",
    "    ]\n",
    ")\n",
    "\n",
    "sgd_opt_space = {'sgd__loss': hp.choice('sgd__loss', ['hinge', 'log']),\n",
    "                 'sgd__alpha': hp.loguniform('sgd__alpha', np.log(1e-5), np.log(10)), \n",
    "                 'sgd__max_iter': scope.int(hp.quniform('sgd__max_iter', 10, 500, 10))}\n",
    "\n",
    "sgd_opt = NestedKFoldOpt(sgd_pipe, sgd_opt_space, partial(f1_score, average='macro'), \n",
    "                        outer_cv=StratifiedKFold(10, shuffle=True, random_state=9), \n",
    "                        inner_cv=StratifiedKFold(10, shuffle=True, random_state=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Encoders require their input to be uniformly strings or numbers. Got ['float', 'str']\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:07<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Encoders require their input to be uniformly strings or numbers. Got ['float', 'str']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_encode.py\", line 173, in _unique_python\n    uniques = sorted(uniques_set)\nTypeError: '<' not supported between instances of 'str' and 'float'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 436, in _process_worker\n    r = call_item()\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 288, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n    return [func(*args, **kwargs)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n    return self.function(*args, **kwargs)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 1068, in _fit_and_predict\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 293, in fit\n    Xt, yt = self._fit(X, y, **fit_params_steps)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 240, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 727, in fit_transform\n    result = self._fit_transform(X, y, _fit_transform_one)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 658, in _fit_transform\n    return Parallel(n_jobs=self.n_jobs)(\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n    return super().__call__(iterable_with_config)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1051, in __call__\n    while self.dispatch_one_batch(iterator):\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 864, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 782, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n    result = ImmediateResult(func)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n    self.results = batch()\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n    return [func(*args, **kwargs)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n    return self.function(*args, **kwargs)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 862, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 838, in fit\n    fit_results = self._fit(\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 93, in _fit\n    result = _unique(Xi, return_counts=return_counts)\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_encode.py\", line 41, in _unique\n    return _unique_python(\n  File \"c:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_encode.py\", line 178, in _unique_python\n    raise TypeError(\nTypeError: Encoders require their input to be uniformly strings or numbers. Got ['float', 'str']\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sgd_opt\u001b[39m.\u001b[39;49mfit(X, y)\n",
      "Cell \u001b[1;32mIn[24], line 70\u001b[0m, in \u001b[0;36mNestedKFoldOpt.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     68\u001b[0m X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m     69\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m---> 70\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnested_kfold(X, y)\n\u001b[0;32m     71\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_hyperparameters_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimize(X, y)\n",
      "Cell \u001b[1;32mIn[24], line 45\u001b[0m, in \u001b[0;36mNestedKFoldOpt.nested_kfold\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     43\u001b[0m X_train, y_train \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39miloc[train_idx], y\u001b[39m.\u001b[39miloc[train_idx]\n\u001b[0;32m     44\u001b[0m X_val, y_val \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39miloc[val_idx], y\u001b[39m.\u001b[39miloc[val_idx]\n\u001b[1;32m---> 45\u001b[0m hypers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimize(X_train, y_train)\n\u001b[0;32m     46\u001b[0m model \u001b[39m=\u001b[39m clone(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mml_model)\u001b[39m.\u001b[39mset_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhypers)\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     47\u001b[0m preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_val)\n",
      "Cell \u001b[1;32mIn[24], line 27\u001b[0m, in \u001b[0;36mNestedKFoldOpt.optimize\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt_type \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbayes\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     26\u001b[0m     obj \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective, data\u001b[39m=\u001b[39m(X, y))\n\u001b[1;32m---> 27\u001b[0m     best \u001b[39m=\u001b[39m fmin(obj, space\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopt_space, algo\u001b[39m=\u001b[39;49mtpe\u001b[39m.\u001b[39;49msuggest, \n\u001b[0;32m     28\u001b[0m                 max_evals\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_evals, return_argmin\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     29\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     30\u001b[0m     loss_metric \u001b[39m=\u001b[39m make_scorer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_metric)\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[39m.\u001b[39mcatch_eval_exceptions \u001b[39m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[39m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m rval\u001b[39m.\u001b[39;49mexhaust()\n\u001b[0;32m    588\u001b[0m \u001b[39mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(trials\u001b[39m.\u001b[39mtrials) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexhaust\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_evals \u001b[39m-\u001b[39;49m n_done, block_until_done\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49masynchronous)\n\u001b[0;32m    365\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    297\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoll_interval_secs)\n\u001b[0;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[39m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mserial_evaluate()\n\u001b[0;32m    302\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[0;32m    303\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials_save_file \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m ctrl \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mCtrl(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials, current_trial\u001b[39m=\u001b[39mtrial)\n\u001b[0;32m    177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdomain\u001b[39m.\u001b[39;49mevaluate(spec, ctrl)\n\u001b[0;32m    179\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mjob exception: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mstr\u001b[39m(e))\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\hyperopt\\base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[39m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     \u001b[39m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[0;32m    886\u001b[0m     \u001b[39m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     pyll_rval \u001b[39m=\u001b[39m pyll\u001b[39m.\u001b[39mrec_eval(\n\u001b[0;32m    888\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpr,\n\u001b[0;32m    889\u001b[0m         memo\u001b[39m=\u001b[39mmemo,\n\u001b[0;32m    890\u001b[0m         print_node_on_error\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[1;32m--> 892\u001b[0m     rval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(pyll_rval)\n\u001b[0;32m    894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(rval, (\u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m, np\u001b[39m.\u001b[39mnumber)):\n\u001b[0;32m    895\u001b[0m     dict_rval \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mfloat\u001b[39m(rval), \u001b[39m\"\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[1;32mIn[24], line 19\u001b[0m, in \u001b[0;36mNestedKFoldOpt.objective\u001b[1;34m(self, x, data)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mobjective\u001b[39m(\u001b[39mself\u001b[39m, x, data):\n\u001b[0;32m     17\u001b[0m     model \u001b[39m=\u001b[39m clone(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mml_model)\u001b[39m.\u001b[39mset_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mx)\n\u001b[1;32m---> 19\u001b[0m     preds \u001b[39m=\u001b[39m cross_val_predict(model, data[\u001b[39m0\u001b[39;49m], data[\u001b[39m1\u001b[39;49m], cv\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minner_cv, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     21\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_metric(data[\u001b[39m1\u001b[39m], preds)\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:986\u001b[0m, in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    984\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    985\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 986\u001b[0m predictions \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    987\u001b[0m     delayed(_fit_and_predict)(\n\u001b[0;32m    988\u001b[0m         clone(estimator), X, y, train, test, verbose, fit_params, method\n\u001b[0;32m    989\u001b[0m     )\n\u001b[0;32m    990\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m splits\n\u001b[0;32m    991\u001b[0m )\n\u001b[0;32m    993\u001b[0m inv_test_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(\u001b[39mlen\u001b[39m(test_indices), dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n\u001b[0;32m    994\u001b[0m inv_test_indices[test_indices] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mlen\u001b[39m(test_indices))\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1061\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1061\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1062\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:938\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    936\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 938\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    939\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    940\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\concurrent\\futures\\_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    457\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 458\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    459\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: Encoders require their input to be uniformly strings or numbers. Got ['float', 'str']"
     ]
    }
   ],
   "source": [
    "sgd_opt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_opt.metrics_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_pipe = Pipeline(\n",
    "    [\n",
    "        ('feat_trans', GBMFeatTransformer(high_card_feats_fs)),\n",
    "        ('over', RandomOverSampler(random_state=9)),\n",
    "        ('lgbm', LGBMClassifier())\n",
    "    ]\n",
    ")\n",
    "\n",
    "lgbm_opt_space = {'lgbm__learning_rate': hp.loguniform('lgbm__learning_rate', np.log(0.001), np.log(0.5)),\n",
    "                  'lgbm__reg_alpha': hp.loguniform('lgbm__reg_alpha', np.log(0.001), np.log(1)),\n",
    "                  'lgbm__reg_lambda': hp.loguniform('lgbm__reg_lambda', np.log(0.001), np.log(1)),\n",
    "                  'lgbm__subsample': hp.uniform('lgbm__subsample', 0.2, 1),\n",
    "                  'lgbm__colsample_bytree': hp.uniform('lgbm__colsample_bytree', 0.2, 1),\n",
    "                  'lgbm__min_child_samples': scope.int(hp.quniform('lgbm__min_child_samples', 1, 100, 1)),\n",
    "                  'lgbm__num_leaves': scope.int(hp.quniform('lgbm__num_leaves', 2, 50, 1)),\n",
    "                  'lgbm__subsample_freq': scope.int(hp.quniform('lgbm__subsample_freq', 1, 10, 1)),\n",
    "                  'lgbm__n_estimators': scope.int(hp.quniform('lgbm__n_estimators', 100, 5000, 1))}\n",
    "\n",
    "lgbm_opt = NestedKFoldOpt(lgbm_pipe, lgbm_opt_space, partial(f1_score, average='macro'), \n",
    "                        outer_cv=StratifiedKFold(10, shuffle=True, random_state=9), \n",
    "                        inner_cv=StratifiedKFold(10, shuffle=True, random_state=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_opt.fit(X_fs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_opt.metrics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_opt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_opt.metrics_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm_pipe = Pipeline(\n",
    "    [\n",
    "        ('feat_trans', GBMFeatTransformer(high_card_feats_fs, EBM=True)),\n",
    "        #('over', RandomOverSampler(random_state=9)),\n",
    "        ('ebm', ExplainableBoostingClassifier(n_jobs=1, validation_size=0))\n",
    "    ]\n",
    ")\n",
    "\n",
    "ebm_opt_space = {'ebm__learning_rate': hp.loguniform('ebm__learning_rate', np.log(0.001), np.log(0.5)),\n",
    "                 #'ebm__validation_size': hp.uniform('ebm__validation_size', 0.05, 0.25),\n",
    "                 #'ebm__early_stopping_rounds': scope.int(hp.quniform('early__stopping_rounds', 5, 100, 1)),\n",
    "                 'ebm__max_rounds': scope.int(hp.quniform('ebm__max_rounds', 10, 3000, 1)),\n",
    "                 'ebm__interactions': scope.int(hp.quniform('ebm__interactions', 0, 20, 1)),\n",
    "                 'ebm__max_leaves': scope.int(hp.quniform('ebm__max_leaves', 2, 10, 1)),\n",
    "                 'ebm__outer_bags': scope.int(hp.quniform('ebm__outer_bags', 8, 16, 1)),\n",
    "                 #'ebm__inner_bags': scope.int(hp.quniform('ebm__inner_bags', 0, 5, 1)),\n",
    "                 'ebm__max_bins': scope.int(hp.quniform('ebm__max_bins', 8, 128, 1)),\n",
    "                 'ebm__max_interaction_bins': scope.int(hp.quniform('ebm__max_interaction_bins', 8, 64, 1)),\n",
    "                 'ebm__min_samples_leaf': scope.int(hp.quniform('ebm__min_samples_leaf', 1, 30, 1))}\n",
    "\n",
    "ebm_opt = NestedKFoldOpt(ebm_pipe, ebm_opt_space, partial(f1_score, average='macro'), \n",
    "                        outer_cv=StratifiedKFold(10, shuffle=True, random_state=9), \n",
    "                        inner_cv=StratifiedKFold(10, shuffle=True, random_state=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm_opt.fit(X_fs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm_opt.metrics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm_opt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm_opt.metrics_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame()\n",
    "for a, m in zip(['rf', 'svm', 'sgd', 'lgbm', 'ebm'], [rf_opt.metrics_dist_, svm_opt.metrics_dist_, \n",
    "                                                      sgd_opt.metrics_dist_, lgbm_opt.metrics_dist_, \n",
    "                                                      ebm_opt.metrics_dist_]):\n",
    "    m['algo'] = [a]*len(m['recall_0'])\n",
    "    df_metrics = pd.concat([df_metrics, pd.DataFrame(m)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_subplots(df_metrics, df_metrics.columns[:-1], 'algo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy\n",
    "print(classification_report(y, DummyClassifier(strategy='stratified').fit(X, y).predict(X)))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "ML Analysis 1",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
