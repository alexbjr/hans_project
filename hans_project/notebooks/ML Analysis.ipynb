{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a8bbbab-c4d6-4d33-9deb-deeee3ddebc2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Imports e config dos módulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eaddd15d-6e31-4192-9589-01f0b17a8fec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Image\n",
    "import warnings\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif, SequentialFeatureSelector, SelectKBest\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer, MissingIndicator\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict, LeaveOneOut, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from boruta import BorutaPy\n",
    "from genetic_selection import GeneticSelectionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d809f8af-ee4a-45dc-9a98-01a13c5bed94",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# pd.set_option('max_columns', None)\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48fb3f5c-53cf-4595-a1ef-9b0b0968096d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b91e37e-aecb-4b0b-b32c-ab379846f9d7",
     "showTitle": true,
     "title": "Read"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mclar\\AppData\\Local\\Temp\\ipykernel_2476\\1568157318.py:1: DtypeWarning: Columns (9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../data/interim/hans_outcome.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/interim/hans_outcome.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e42b76e-9dac-40e9-a095-20edbd7528fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113837, 39)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d748a056-f7cc-40a9-946a-93958a937811",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Agrupamento e remoção de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a54241f-ac2a-4605-9b27-d7bb118a3720",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "target = 'TPALTA_N'\n",
    "feats = df.drop(target, axis=1).columns\n",
    "num_feats = [feat for feat in feats if df[feat].dtype != 'O']\n",
    "cat_feats = [feat for feat in feats if feat not in num_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77a9fbf9-0637-4fbe-8cce-a620a1bdbfb9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# remove colunas com classes muito dominantes\n",
    "def drop_low_variance(col):\n",
    "    if df[col].nunique() == 1:\n",
    "        return True\n",
    "    elif df[col].value_counts(1).iloc[0] > 0.9:\n",
    "        return True\n",
    "    elif df[col].value_counts().iloc[0] < df[col].isna().sum():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "low_var_feats = [col for col in cat_feats if drop_low_variance(col)]\n",
    "cat_feats = [feat for feat in cat_feats if feat not in low_var_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2798c17-b237-4d1b-8e32-1882cddb115e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DT_DIAG',\n",
       " 'CS_SEXO',\n",
       " 'CS_ESCOL_N',\n",
       " 'DTINICTRAT',\n",
       " 'UFATUAL',\n",
       " 'DT_NOTI_AT',\n",
       " 'DTALTA_N']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_feats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b6495ac-933c-4d97-a2e4-aa072274df61",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# ML Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5005bbe-2f3f-407a-aa28-edca82e535d1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Feature transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14e83163-fd37-4e7f-84c6-dc19494a2e29",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class GBMFeatTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, EBM=False):\n",
    "        self.EBM = EBM\n",
    "        self.num_feats_means = dict()\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        if self.EBM:\n",
    "            for col in X.columns:\n",
    "                if X[col].dtype != 'O':\n",
    "                    self.num_feats_means[col] = X[col].mean()\n",
    "        return self\n",
    "            \n",
    "    def transform(self, X, y=None):\n",
    "        ret = X.copy()\n",
    "        if not self.EBM:\n",
    "            for col in ret.columns:\n",
    "                if ret[col].dtype == 'O':\n",
    "                    ret[col] = ret[col].astype('category')\n",
    "        else:\n",
    "            for col in self.num_feats_means:\n",
    "                ret[col] = ret[col].fillna(self.num_feats_means[col])\n",
    "        return ret\n",
    "        \n",
    "general_num_transformer = FeatureUnion(    \n",
    "    [\n",
    "        ('num_pipe', Pipeline(\n",
    "            [\n",
    "                ('norm', StandardScaler()),\n",
    "                ('nan_input', SimpleImputer())\n",
    "            ]\n",
    "        )),\n",
    "        ('nan_flag', MissingIndicator(error_on_new=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "general_feat_transformer = ColumnTransformer(\n",
    "    [\n",
    "        ('num_trans', general_num_transformer, num_feats),\n",
    "        ('cat_trans', OneHotEncoder(handle_unknown='ignore'), cat_feats)    \n",
    "    ],\n",
    "    remainder='passthrough', sparse_threshold=0\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5b501ad-eb34-420d-aed8-a3aecb69f891",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Nested K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b595d88-a168-4def-8b1f-047615f20b90",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class NestedKFoldOpt():\n",
    "    def __init__(self, ml_model, opt_space, loss_metric, outer_cv, inner_cv, \n",
    "                 opt_type='bayes', max_evals=10):\n",
    "        self.ml_model = ml_model\n",
    "        self.opt_space = opt_space\n",
    "        self.loss_metric = loss_metric\n",
    "        self.opt_type = opt_type\n",
    "        self.max_evals = max_evals\n",
    "        self.outer_cv = outer_cv\n",
    "        self.inner_cv = inner_cv\n",
    "        self.metrics_ = None\n",
    "        self.metrics_oof_ = None\n",
    "        self.metrics_dist_ = None\n",
    "        self.best_hyperparameters_ = None\n",
    "        \n",
    "    def objective(self, x, data):\n",
    "        model = clone(self.ml_model).set_params(**x)\n",
    "        \n",
    "        preds = cross_val_predict(model, data[0], data[1], cv=self.inner_cv, n_jobs=-1)\n",
    "        \n",
    "        return -self.loss_metric(data[1], preds)     \n",
    "        \n",
    "    \n",
    "    def optimize(self, X, y):\n",
    "        if self.opt_type == 'bayes':\n",
    "            obj = partial(self.objective, data=(X, y))\n",
    "            best = fmin(obj, space=self.opt_space, algo=tpe.suggest, \n",
    "                        max_evals=self.max_evals, return_argmin=False)\n",
    "        else:\n",
    "            loss_metric = make_scorer(self.loss_metric)\n",
    "            best = GridSearchCV(self.ml_model, self.opt_space, scoring=loss_metric,\n",
    "                                n_jobs=-1, cv=self.inner_cv, verbose=3).\\\n",
    "                   fit(X, y).best_params_\n",
    "        return best\n",
    "    \n",
    "    def nested_kfold(self, X, y):\n",
    "        recall_0 = []\n",
    "        recall_1 = []\n",
    "        precision_0 = []\n",
    "        precision_1 = []\n",
    "        oof = np.zeros(len(X))\n",
    "        for train_idx, val_idx in self.outer_cv.split(X, y):\n",
    "            X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "            X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "            hypers = self.optimize(X_train, y_train)\n",
    "            model = clone(self.ml_model).set_params(**hypers).fit(X_train, y_train)\n",
    "            preds = model.predict(X_val)\n",
    "            oof[val_idx] = preds \n",
    "            recall_0.append(recall_score(y_val, preds, pos_label=0))\n",
    "            recall_1.append(recall_score(y_val, preds, pos_label=1))\n",
    "            precision_0.append(precision_score(y_val, preds, pos_label=0))\n",
    "            precision_1.append(precision_score(y_val, preds, pos_label=1))\n",
    "        self.metrics_ = pd.DataFrame({'recall': [np.mean(recall_0), np.mean(recall_1)],\n",
    "                                      'recall_std': [np.std(recall_0), np.std(recall_1)],\n",
    "                                      'precision': [np.mean(precision_0), np.mean(precision_1)],\n",
    "                                      'precision_std': [np.std(precision_0), np.std(precision_1)]},\n",
    "                                     index=['class_0', 'class_1'])\n",
    "        self.metrics_oof_ = pd.DataFrame({'recall': [recall_score(y, oof, pos_label=0), recall_score(y, oof)],\n",
    "                                          'precision': [precision_score(y, oof, pos_label=0), precision_score(y, oof)],\n",
    "                                          'f1 score': [f1_score(y, oof, pos_label=0), f1_score(y, oof)],\n",
    "                                          'accuracy': [accuracy_score(y, oof)],\n",
    "                                         },\n",
    "                                         index=['class_0', 'class_1'])\n",
    "        self.metrics_dist_ = {'recall_0': recall_0, 'recall_1': recall_1,\n",
    "                              'precision_0': precision_0, 'precision_1': precision_1}\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        X = X.copy()\n",
    "        y = y.copy()\n",
    "        self.nested_kfold(X, y)\n",
    "        self.best_hyperparameters_ = self.optimize(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6598362a-dae2-453e-bc72-262f45a60d69",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X = df[num_feats + cat_feats].copy()\n",
    "le = LabelEncoder().fit(df[target])\n",
    "y = pd.Series(le.transform(df[target]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "248cde31-a91c-4bc9-8e51-404b16a73e48",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "62e11928-783c-4fc8-993c-11c04ec45bb2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "base_model = RandomForestClassifier(n_jobs=-1, max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d91ae324-01a8-4e12-a228-1dc6aa0fe161",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_num = GBMFeatTransformer().fit_transform(X)\n",
    "for col in X_num.columns:\n",
    "    if X_num[col].dtype.name == 'category':\n",
    "        X_num[col] = X_num[col].cat.codes\n",
    "    else:\n",
    "        X_num[col].fillna(X_num[col].median(), inplace=True)\n",
    "        \n",
    "columns = X_num.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5ecd2d5-adeb-4343-a304-114c7824bd4e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.05      0.09      6880\n",
      "           1       0.94      1.00      0.97    106957\n",
      "\n",
      "    accuracy                           0.94    113837\n",
      "   macro avg       0.93      0.52      0.53    113837\n",
      "weighted avg       0.94      0.94      0.92    113837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, cross_val_predict(base_model, X_num, y, n_jobs=-1,\n",
    "  cv=StratifiedKFold(shuffle=True, random_state=9))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d69e16a8-b362-46d1-98d2-52e9f6afaa8e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "996ec863-02f8-48f5-a42a-5ebf44b2896a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m bor_selector \u001b[39m=\u001b[39m BorutaPy(base_model, n_estimators\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m, perc\u001b[39m=\u001b[39m\u001b[39m90\u001b[39m, max_iter\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m bor_selector\u001b[39m.\u001b[39;49mfit(X_num\u001b[39m.\u001b[39;49mvalues, y\u001b[39m.\u001b[39;49mvalues)\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:201\u001b[0m, in \u001b[0;36mBorutaPy.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[0;32m    189\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[39m    Fits the Boruta feature selection with the provided estimator.\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39m        The target values.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 201\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y)\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:285\u001b[0m, in \u001b[0;36mBorutaPy._fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator\u001b[39m.\u001b[39mset_params(random_state\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n\u001b[0;32m    284\u001b[0m \u001b[39m# add shadow attributes, shuffle them and train estimator, get imps\u001b[39;00m\n\u001b[1;32m--> 285\u001b[0m cur_imp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_add_shadows_get_imps(X, y, dec_reg)\n\u001b[0;32m    287\u001b[0m \u001b[39m# get the threshold of shadow importances we will use for rejection\u001b[39;00m\n\u001b[0;32m    288\u001b[0m imp_sha_max \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mpercentile(cur_imp[\u001b[39m1\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mperc)\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:412\u001b[0m, in \u001b[0;36mBorutaPy._add_shadows_get_imps\u001b[1;34m(self, X, y, dec_reg)\u001b[0m\n\u001b[0;32m    410\u001b[0m x_sha \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mapply_along_axis(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_shuffle, \u001b[39m0\u001b[39m, x_sha)\n\u001b[0;32m    411\u001b[0m \u001b[39m# get importance of the merged matrix\u001b[39;00m\n\u001b[1;32m--> 412\u001b[0m imp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_imp(np\u001b[39m.\u001b[39;49mhstack((x_cur, x_sha)), y)\n\u001b[0;32m    413\u001b[0m \u001b[39m# separate importances of real and shadow features\u001b[39;00m\n\u001b[0;32m    414\u001b[0m imp_sha \u001b[39m=\u001b[39m imp[x_cur_w:]\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:384\u001b[0m, in \u001b[0;36mBorutaPy._get_imp\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_imp\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[0;32m    383\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 384\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[0;32m    385\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    386\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mPlease check your X and y variable. The provided\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    387\u001b[0m                          \u001b[39m'\u001b[39m\u001b[39mestimator cannot be fitted to your data.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e))\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    462\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    464\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    465\u001b[0m ]\n\u001b[0;32m    467\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    474\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    475\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    476\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    477\u001b[0m )(\n\u001b[0;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    479\u001b[0m         t,\n\u001b[0;32m    480\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    481\u001b[0m         X,\n\u001b[0;32m    482\u001b[0m         y,\n\u001b[0;32m    483\u001b[0m         sample_weight,\n\u001b[0;32m    484\u001b[0m         i,\n\u001b[0;32m    485\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    486\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    487\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    488\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    489\u001b[0m     )\n\u001b[0;32m    490\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    491\u001b[0m )\n\u001b[0;32m    493\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1061\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1061\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1062\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:938\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    936\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 938\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    939\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    940\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\multiprocessing\\pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 768\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    769\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[0;32m    770\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\multiprocessing\\pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    605\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[0;32m    606\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 607\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    608\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32mc:\\Users\\mclar\\anaconda3\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bor_selector = BorutaPy(base_model, n_estimators='auto', perc=90, max_iter=100)\n",
    "bor_selector.fit(X_num.values, y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "256c75f5-069f-4295-a1fb-535dfd05ef6d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "columns[bor_selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b796d0c7-e0ec-488a-8952-359bded04d2f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bottom_boruta = columns[bor_selector.ranking_.argsort()[-(len(columns)-30):]]\n",
    "bottom_boruta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8bacfed-89b3-4904-8e64-9b0ea57dd998",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Sequential Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4db03f3-89c5-4167-89d6-0a83eed7a122",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sb_selector = SequentialFeatureSelector(base_model, n_features_to_select=30, direction='backward',\n",
    "                                        scoring=make_scorer(f1_score, average='macro'), \n",
    "                                        cv=StratifiedKFold(shuffle=True, random_state=9), n_jobs=-1)\n",
    "sb_selector.fit(X_num, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c30f4472-1308-4690-a0ce-04bf12f32027",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bottom_sb = columns[~sb_selector.get_support()]\n",
    "bottom_sb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd658ae3-5639-4552-a24b-03f70ea8a36a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### M.I Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "afbfaca8-1940-44de-b80a-f4d9579d8393",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mi_selector = SelectKBest(mutual_info_classif, k=30).fit(X_num, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5fd1f3e-b14f-4735-9f30-bf2c32c07a72",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bottom_mi = columns[~mi_selector.get_support()]\n",
    "bottom_mi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a021df5-e9ea-4023-a8dc-1efe43f4591a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c6ffed2-ab18-4b63-a92a-615767b7e816",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ga_selector = GeneticSelectionCV(base_model, cv=StratifiedKFold(shuffle=True, random_state=9), \n",
    "                                 scoring=make_scorer(f1_score, average='macro'), max_features=30, \n",
    "                                 n_population=100, n_generations=40, n_gen_no_change=10)\n",
    "ga_selector.fit(X_num, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "996ab17e-9ab8-4090-8fa3-89c53501cdd9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bottom_ga = columns[~ga_selector.get_support()]\n",
    "bottom_ga"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc3444b0-698e-41ea-a5ef-7cbe91d4ed82",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Aggregation of the methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c71ba497-aad2-4198-826f-84a735b747ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "counts = pd.Series(dict(Counter(np.hstack([bottom_boruta, bottom_sb, bottom_mi, bottom_ga]))))\n",
    "# counts = pd.Series(dict(Counter(np.hstack([bottom_boruta, bottom_mi]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8d4d9e8-e77b-4fe5-8ae5-6f438065e2ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cols_to_decide = counts[counts>2].index\n",
    "cols_to_decide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "722c893b-41c2-403c-be7b-519d669cdf29",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cols_to_remove = cols_to_decide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5308989a-c397-4aa6-aac4-420bf0354aa9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_fs = X.drop(cols_to_remove, axis=1)\n",
    "X_fs.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf295ce3-61b8-432c-ad8e-0c96fc6d183d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Algorithms Comparison"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f9e8f10-9b4a-452a-bd48-daedf6587d32",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "faf32c96-8e7d-4997-9a9e-4ed2b020696a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lr_pipe = Pipeline(\n",
    "  [\n",
    "      ('feat_trans', general_feat_transformer),\n",
    "      ('over', RandomOverSampler(random_state=9)),\n",
    "      ('logreg', LogisticRegression(random_state = 0))\n",
    "]\n",
    ")\n",
    "\n",
    "lr_opt_space = {'logreg__solver': hp.choice('logreg__solver', ['liblinear', 'lbfgs']),\n",
    "                'logreg__C': hp.loguniform('logreg__C', np.log(1e-5), np.log(100))}\n",
    "               \n",
    "lr_opt_space = {'logreg__warm_start' : hp.choice('logreg__warm_start', [True, False]),\n",
    "                'logreg__fit_intercept' : hp.choice('logreg__fit_intercept', [True, False]),\n",
    "                'logreg__tol' : hp.uniform('logreg__tol', 0.00001, 0.0001),\n",
    "                'logreg__C' : hp.uniform('logreg__C', 0.05, 3),\n",
    "                'logreg__solver' : hp.choice('logreg__solver', ['newton-cg', 'lbfgs', 'liblinear']),\n",
    "                'logreg__multi_class' : 'auto',\n",
    "                'logreg__class_weight' : 'balanced'}\n",
    "\n",
    "lr_opt = NestedKFoldOpt(lr_pipe, lr_opt_space, partial(f1_score, average='macro'), \n",
    "                      outer_cv=StratifiedKFold(2, shuffle=True, random_state=9), \n",
    "                      inner_cv=StratifiedKFold(2, shuffle=True, random_state=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad7862e5-669b-41cb-a89a-d261867943ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lr_opt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7813b78d-3086-48dd-875a-52d88ea85e38",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lr_opt.metrics_oof_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf156317-6cf6-48e5-a323-b9b4ac347c8a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lr_opt.fit(X_fs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7930884-6fcb-49e5-86d3-ad3622dec472",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lr_opt.metrics_oof_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27dd2fae-3ab9-46cb-b305-4d8d231b183e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rf_pipe = Pipeline(\n",
    "    [\n",
    "        ('feat_trans', GBMFeatTransformer(high_card_feats_fs)),\n",
    "        ('over', RandomOverSampler(random_state=9)),\n",
    "        ('rf', LGBMClassifier(boosting_type='rf', subsample_freq=1, min_child_samples=1))\n",
    "    ]\n",
    ")\n",
    "\n",
    "rf_opt_space = {'rf__n_estimators': scope.int(hp.quniform('rf__n_estimators', 50, 300, 10)),\n",
    "                'rf__num_leaves': scope.int(hp.quniform('num_leaves', 2, 100, 1)),\n",
    "                'rf__subsample': hp.uniform('rf__subsample', 0.3, 0.95),\n",
    "                'rf__colsample_bytree': hp.uniform('rf__colsample_bytree', 0.3, 0.95)}\n",
    "\n",
    "rf_opt = NestedKFoldOpt(rf_pipe, rf_opt_space, partial(f1_score, average='macro'), \n",
    "                        outer_cv=StratifiedKFold(10, shuffle=True, random_state=9), \n",
    "                        inner_cv=StratifiedKFold(10, shuffle=True, random_state=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_opt.fit(X_fs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_opt.metrics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_opt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_opt.metrics_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pipe = Pipeline(\n",
    "    [\n",
    "        ('feat_trans', general_feat_transformer),\n",
    "        ('over', RandomOverSampler(random_state=9)),\n",
    "        ('svm', SVC())\n",
    "    ]\n",
    ")\n",
    "\n",
    "svm_opt_space = {'svm__C': hp.loguniform('svm__C', np.log(1e-5), np.log(100)),\n",
    "                 'svm__gamma': hp.loguniform('svm__gamma', np.log(1e-6), np.log(10))}\n",
    "\n",
    "svm_opt = NestedKFoldOpt(svm_pipe, svm_opt_space, partial(f1_score, average='macro'), \n",
    "                        outer_cv=StratifiedKFold(10, shuffle=True, random_state=9), \n",
    "                        inner_cv=StratifiedKFold(10, shuffle=True, random_state=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_opt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_opt.metrics_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_pipe = Pipeline(\n",
    "    [\n",
    "        ('feat_trans', general_feat_transformer),\n",
    "        ('over', RandomOverSampler(random_state=9)),\n",
    "        ('sgd', SGDClassifier())\n",
    "    ]\n",
    ")\n",
    "\n",
    "sgd_opt_space = {'sgd__loss': hp.choice('sgd__loss', ['hinge', 'log']),\n",
    "                 'sgd__alpha': hp.loguniform('sgd__alpha', np.log(1e-5), np.log(10)), \n",
    "                 'sgd__max_iter': scope.int(hp.quniform('sgd__max_iter', 10, 500, 10))}\n",
    "\n",
    "sgd_opt = NestedKFoldOpt(sgd_pipe, sgd_opt_space, partial(f1_score, average='macro'), \n",
    "                        outer_cv=StratifiedKFold(10, shuffle=True, random_state=9), \n",
    "                        inner_cv=StratifiedKFold(10, shuffle=True, random_state=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_opt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_opt.metrics_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_pipe = Pipeline(\n",
    "    [\n",
    "        ('feat_trans', GBMFeatTransformer(high_card_feats_fs)),\n",
    "        ('over', RandomOverSampler(random_state=9)),\n",
    "        ('lgbm', LGBMClassifier())\n",
    "    ]\n",
    ")\n",
    "\n",
    "lgbm_opt_space = {'lgbm__learning_rate': hp.loguniform('lgbm__learning_rate', np.log(0.001), np.log(0.5)),\n",
    "                  'lgbm__reg_alpha': hp.loguniform('lgbm__reg_alpha', np.log(0.001), np.log(1)),\n",
    "                  'lgbm__reg_lambda': hp.loguniform('lgbm__reg_lambda', np.log(0.001), np.log(1)),\n",
    "                  'lgbm__subsample': hp.uniform('lgbm__subsample', 0.2, 1),\n",
    "                  'lgbm__colsample_bytree': hp.uniform('lgbm__colsample_bytree', 0.2, 1),\n",
    "                  'lgbm__min_child_samples': scope.int(hp.quniform('lgbm__min_child_samples', 1, 100, 1)),\n",
    "                  'lgbm__num_leaves': scope.int(hp.quniform('lgbm__num_leaves', 2, 50, 1)),\n",
    "                  'lgbm__subsample_freq': scope.int(hp.quniform('lgbm__subsample_freq', 1, 10, 1)),\n",
    "                  'lgbm__n_estimators': scope.int(hp.quniform('lgbm__n_estimators', 100, 5000, 1))}\n",
    "\n",
    "lgbm_opt = NestedKFoldOpt(lgbm_pipe, lgbm_opt_space, partial(f1_score, average='macro'), \n",
    "                        outer_cv=StratifiedKFold(10, shuffle=True, random_state=9), \n",
    "                        inner_cv=StratifiedKFold(10, shuffle=True, random_state=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_opt.fit(X_fs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_opt.metrics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_opt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_opt.metrics_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm_pipe = Pipeline(\n",
    "    [\n",
    "        ('feat_trans', GBMFeatTransformer(high_card_feats_fs, EBM=True)),\n",
    "        #('over', RandomOverSampler(random_state=9)),\n",
    "        ('ebm', ExplainableBoostingClassifier(n_jobs=1, validation_size=0))\n",
    "    ]\n",
    ")\n",
    "\n",
    "ebm_opt_space = {'ebm__learning_rate': hp.loguniform('ebm__learning_rate', np.log(0.001), np.log(0.5)),\n",
    "                 #'ebm__validation_size': hp.uniform('ebm__validation_size', 0.05, 0.25),\n",
    "                 #'ebm__early_stopping_rounds': scope.int(hp.quniform('early__stopping_rounds', 5, 100, 1)),\n",
    "                 'ebm__max_rounds': scope.int(hp.quniform('ebm__max_rounds', 10, 3000, 1)),\n",
    "                 'ebm__interactions': scope.int(hp.quniform('ebm__interactions', 0, 20, 1)),\n",
    "                 'ebm__max_leaves': scope.int(hp.quniform('ebm__max_leaves', 2, 10, 1)),\n",
    "                 'ebm__outer_bags': scope.int(hp.quniform('ebm__outer_bags', 8, 16, 1)),\n",
    "                 #'ebm__inner_bags': scope.int(hp.quniform('ebm__inner_bags', 0, 5, 1)),\n",
    "                 'ebm__max_bins': scope.int(hp.quniform('ebm__max_bins', 8, 128, 1)),\n",
    "                 'ebm__max_interaction_bins': scope.int(hp.quniform('ebm__max_interaction_bins', 8, 64, 1)),\n",
    "                 'ebm__min_samples_leaf': scope.int(hp.quniform('ebm__min_samples_leaf', 1, 30, 1))}\n",
    "\n",
    "ebm_opt = NestedKFoldOpt(ebm_pipe, ebm_opt_space, partial(f1_score, average='macro'), \n",
    "                        outer_cv=StratifiedKFold(10, shuffle=True, random_state=9), \n",
    "                        inner_cv=StratifiedKFold(10, shuffle=True, random_state=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm_opt.fit(X_fs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm_opt.metrics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm_opt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm_opt.metrics_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame()\n",
    "for a, m in zip(['rf', 'svm', 'sgd', 'lgbm', 'ebm'], [rf_opt.metrics_dist_, svm_opt.metrics_dist_, \n",
    "                                                      sgd_opt.metrics_dist_, lgbm_opt.metrics_dist_, \n",
    "                                                      ebm_opt.metrics_dist_]):\n",
    "    m['algo'] = [a]*len(m['recall_0'])\n",
    "    df_metrics = pd.concat([df_metrics, pd.DataFrame(m)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_subplots(df_metrics, df_metrics.columns[:-1], 'algo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy\n",
    "print(classification_report(y, DummyClassifier(strategy='stratified').fit(X, y).predict(X)))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "ML Analysis 1",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
